{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import util\n",
    "import rans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../pytorch-wavenet'))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "\n",
    "from wavenet_vocoder import WaveNet\n",
    "from audio_data import AudioDataset\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from util import parameter_count\n",
    "\n",
    "from apex import amp\n",
    "import mpld3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_precision = 8\n",
    "obs_precision = 14\n",
    "q_precision = 14\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "np.seterr(over='raise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and decoding with uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_bits [172  47]\n",
      "state 1 (2147483648, ())\n",
      "state 2 (140737488367532, ())\n",
      "state (2147483648, ())\n",
      "recovered_bits [172  47]\n"
     ]
    }
   ],
   "source": [
    "range_exp = 8\n",
    "\n",
    "other_bits = rng.randint(1 << range_exp, size=2, dtype=np.uint32)\n",
    "print(\"other_bits\", other_bits)\n",
    "\n",
    "state = rans.x_init\n",
    "print(\"state 1\", state)\n",
    "state = util.uniforms_append(range_exp)(state, other_bits)\n",
    "print(\"state 2\", state)\n",
    "\n",
    "state, recovered_bits = util.uniforms_pop(range_exp, other_bits.shape[0])(state)\n",
    "print(\"state\", state)\n",
    "print(\"recovered_bits\", recovered_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and decoding with categorical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def categoricals_append(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    def append(state, data):\n",
    "        data = np.ravel(data)\n",
    "        return non_uniforms_append(precision, cdfs)(state, data)\n",
    "    return append\n",
    "\n",
    "def categoricals_pop(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    data_shape = np.shape(probs)[:-1]\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    ppfs = [categorical_ppf(p, precision) for p in probs]\n",
    "\n",
    "    def pop(state):\n",
    "        state, symbols = non_uniforms_pop(precision, ppfs, cdfs)(state)\n",
    "        return state, np.reshape(symbols, data_shape)\n",
    "    return pop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# range_exp = 3\n",
    "precision = 14\n",
    "# probs = np.array([[1/32, 31/32], [1/4, 3/4]])\n",
    "probs = F.softmax(torch.rand(3, 8), dim=-1).numpy()\n",
    "\n",
    "data = np.array([1, 2, 3])# rng.randint(1 << range_exp, size=2, dtype=np.uint32)\n",
    "print(\"data\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 1 (2147483648, ())\n",
      "state 2 (857489215995, ())\n"
     ]
    }
   ],
   "source": [
    "state = rans.x_init\n",
    "print(\"state 1\", state)\n",
    "state = util.categoricals_append(probs, precision)(state, data)\n",
    "print(\"state 2\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2147483648, ()), array([3]))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, recovered_data = util.categoricals_pop(probs[2:3, :], precision)(state)\n",
    "state, recovered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7007908502, ()), array([2]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.categoricals_pop(probs[-3:-2, :], precision)(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding with WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(1)\n",
    "prfx = '../pytorch-wavenet'\n",
    "mpld3.disable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs {'out_channels': 256, 'layers': 20, 'stacks': 2, 'residual_channels': 512, 'gate_channels': 512, 'skip_out_channels': 512, 'kernel_size': 3, 'dropout': 0.05, 'cin_channels': -1, 'gin_channels': -1, 'weight_normalization': True, 'scalar_input': False, 'legacy': False}\n"
     ]
    }
   ],
   "source": [
    "snapshot_name = \"48\"\n",
    "with open(f\"{prfx}/configs/{snapshot_name}.json\") as f:\n",
    "    data = f.read()\n",
    "config = json.loads(data)\n",
    "wavenet_args = config[\"wavenet_args\"]\n",
    "train_args = config[\"train_args\"]\n",
    "batch_size = train_args[\"batch_size\"]\n",
    "epochs = train_args[\"epochs\"]\n",
    "weight_decay  = train_args[\"weight_decay\"]\n",
    "continue_training_at_step = train_args[\"continue_training_at_step\"]\n",
    "snapshot_path = f\"snapshots/{snapshot_name}\"\n",
    "snapshot_interval = train_args[\"snapshot_interval\"]\n",
    "lr = train_args[\"lr\"]\n",
    "device_name = config[\"device\"]\n",
    "dataset_path = config[\"dataset_path\"]\n",
    "load_path = config[\"load_path\"]\n",
    "type = config.get(\"type\", \"wavenet\")\n",
    "assert type == \"wavenet\"\n",
    "class WaveNetWrapper(WaveNet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        print(\"kwargs\", kwargs)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return super().forward(self.one_hot(input))\n",
    "    \n",
    "    def one_hot(self, input):\n",
    "        one_hot_input = torch.zeros(input.size(0), self.out_channels, input.size(1), device=torch.device('cpu'))\n",
    "        one_hot_input.scatter_(1, input.unsqueeze(1), 1.)\n",
    "        return one_hot_input\n",
    "model = WaveNetWrapper(**wavenet_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset has 75535 items\n",
      "each item has length 32744\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioDataset(f'{prfx}/{dataset_path}', model.receptive_field*8)        \n",
    "\n",
    "print('the dataset has ' + str(len(dataset)) + ' items')\n",
    "print(f'each item has length {dataset.len_sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dict = torch.load(f\"{prfx}/snapshots/{snapshot_name}/{snapshot_name}_34000\", map_location='cpu')\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(checkpoint_dict['model'])\n",
    "model = model.module\n",
    "# model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[1].long().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[:,  1:]\n",
    "torch.manual_seed(0)\n",
    "y_hat = model(x)[:, :, :-1]\n",
    "loss = F.cross_entropy(y_hat, y, reduction='sum') / x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1238, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 / ((loss/math.log(2)) / x.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.1229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x_input = torch.cat([torch.zeros_like(x), x], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "all_x_output = model(all_x_input).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveNetWrapper(\n",
       "  (first_conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "  (conv_layers): ModuleList(\n",
       "    (0): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (4): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (5): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (6): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (8): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(512,), dilation=(256,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (9): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1024,), dilation=(512,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (10): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (11): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (12): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (13): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (14): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (15): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (16): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (17): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (18): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(512,), dilation=(256,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (19): ResidualConv1dGLU(\n",
       "      (conv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1024,), dilation=(512,))\n",
       "      (conv1x1_out): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conv1x1_skip): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (last_conv_layers): ModuleList(\n",
       "    (0): ReLU(inplace=True)\n",
       "    (1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching worked!\n"
     ]
    }
   ],
   "source": [
    "out = model.incremental_forward(softmax=False,quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2772e+00, -7.2704e+00, -7.2539e+00, -7.2024e+00, -7.2312e+00,\n",
       "        -6.8722e+00, -6.2317e+00, -6.0768e+00, -5.8338e+00, -5.2100e+00,\n",
       "        -5.0316e+00, -4.8122e+00, -4.8287e+00, -4.8191e+00, -4.7682e+00,\n",
       "        -4.8402e+00, -5.0198e+00, -4.8576e+00, -4.6458e+00, -4.6525e+00,\n",
       "        -4.5661e+00, -4.4765e+00, -4.4847e+00, -4.2631e+00, -4.5779e+00,\n",
       "        -4.7897e+00, -4.6694e+00, -5.1281e+00, -4.8903e+00, -5.2669e+00,\n",
       "        -5.0791e+00, -4.8225e+00, -5.4319e+00, -5.7692e+00, -5.0441e+00,\n",
       "        -5.2016e+00, -4.9732e+00, -4.8302e+00, -5.1365e+00, -5.2112e+00,\n",
       "        -5.3023e+00, -5.3787e+00, -5.5397e+00, -5.5151e+00, -5.9245e+00,\n",
       "        -5.8163e+00, -5.9782e+00, -5.2996e+00, -5.4737e+00, -5.5200e+00,\n",
       "        -5.5589e+00, -5.4932e+00, -5.2754e+00, -5.1180e+00, -5.1033e+00,\n",
       "        -4.5851e+00, -5.0620e+00, -4.9830e+00, -4.8531e+00, -4.7613e+00,\n",
       "        -4.5676e+00, -4.4176e+00, -4.2322e+00, -3.9553e+00, -3.8968e+00,\n",
       "        -3.3153e+00, -3.3538e+00, -3.3101e+00, -3.0109e+00, -3.1101e+00,\n",
       "        -3.0272e+00, -2.8937e+00, -2.5479e+00, -2.3547e+00, -2.2384e+00,\n",
       "        -2.1422e+00, -2.1057e+00, -1.9177e+00, -1.9505e+00, -1.6627e+00,\n",
       "        -1.4502e+00, -1.2524e+00, -1.2979e+00, -1.4642e+00, -1.2674e+00,\n",
       "        -1.1984e+00, -1.2984e+00, -9.8874e-01, -1.0098e+00, -9.0500e-01,\n",
       "        -5.9621e-01, -6.3090e-01, -6.4068e-01, -3.6713e-01, -2.6614e-01,\n",
       "        -2.1808e-01, -8.2798e-02,  5.2081e-02, -1.1509e-02,  8.8111e-02,\n",
       "         2.8962e-01,  2.0820e-01,  2.7092e-01,  2.6777e-01,  1.4003e-01,\n",
       "         1.6154e-01,  2.4647e-01,  2.8614e-01,  2.2642e-01,  1.0451e-01,\n",
       "         8.3623e-02,  1.9322e-01,  2.5955e-01,  8.5133e-02,  2.7264e-01,\n",
       "         5.0146e-01,  2.7448e-01,  4.2287e-01,  3.1544e-01,  4.5041e-01,\n",
       "         3.7044e-01,  5.6405e-01,  4.8448e-01,  1.3450e-01, -9.0373e-02,\n",
       "         5.7772e-02,  1.0677e-01,  1.8767e-01, -4.9907e-03,  6.4354e-02,\n",
       "        -2.7083e-01, -1.8163e-01, -1.7749e-01, -5.6782e-02,  1.2425e-01,\n",
       "         2.3342e-02,  1.4714e-01, -5.8618e-02, -1.9365e-01, -1.2403e-01,\n",
       "        -1.3453e-01,  1.1378e-02,  1.7016e-02, -8.6820e-02,  3.9396e-02,\n",
       "        -8.6210e-02, -1.4753e-02, -9.2780e-02,  3.4127e-02,  3.6955e-02,\n",
       "        -1.3153e-01, -1.4904e-01, -1.4469e-01, -1.5524e-01, -3.3728e-01,\n",
       "        -4.2579e-01, -4.5676e-01, -3.9222e-01, -5.9317e-01, -8.0170e-01,\n",
       "        -8.5416e-01, -8.6094e-01, -1.0332e+00, -1.3421e+00, -1.4295e+00,\n",
       "        -1.6835e+00, -1.8187e+00, -1.8138e+00, -1.8555e+00, -1.9938e+00,\n",
       "        -2.1055e+00, -2.3697e+00, -2.3980e+00, -2.3252e+00, -2.6069e+00,\n",
       "        -2.6829e+00, -2.8424e+00, -3.0395e+00, -3.0659e+00, -3.1714e+00,\n",
       "        -3.3547e+00, -3.4451e+00, -3.5045e+00, -3.8124e+00, -4.2795e+00,\n",
       "        -4.4315e+00, -4.5110e+00, -4.5288e+00, -4.8807e+00, -5.1203e+00,\n",
       "        -5.3122e+00, -5.0875e+00, -5.5725e+00, -5.3004e+00, -5.7700e+00,\n",
       "        -5.5036e+00, -5.8694e+00, -6.0784e+00, -5.7300e+00, -5.9752e+00,\n",
       "        -5.9639e+00, -5.5136e+00, -6.3171e+00, -5.9742e+00, -5.9269e+00,\n",
       "        -6.0338e+00, -6.1577e+00, -6.1933e+00, -6.3998e+00, -6.0635e+00,\n",
       "        -5.8210e+00, -6.0519e+00, -5.7662e+00, -6.2019e+00, -5.8175e+00,\n",
       "        -5.4155e+00, -5.4411e+00, -5.2152e+00, -5.2619e+00, -5.0795e+00,\n",
       "        -5.3696e+00, -4.8555e+00, -5.0320e+00, -4.8302e+00, -4.6054e+00,\n",
       "        -5.0078e+00, -5.0252e+00, -5.2503e+00, -5.3520e+00, -4.7763e+00,\n",
       "        -4.6744e+00, -4.7825e+00, -4.7060e+00, -4.3996e+00, -4.4651e+00,\n",
       "        -4.3253e+00, -4.5765e+00, -5.0021e+00, -4.6499e+00, -4.8495e+00,\n",
       "        -4.9247e+00, -5.1852e+00, -5.6371e+00, -5.5545e+00, -5.6588e+00,\n",
       "        -5.5653e+00, -5.5671e+00, -5.8616e+00, -6.0053e+00, -6.1686e+00,\n",
       "        -6.6033e+00, -6.8457e+00, -6.6842e+00, -6.6027e+00, -6.5712e+00,\n",
       "        -6.2666e+00])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2772e+00, -7.2704e+00, -7.2539e+00, -7.2024e+00, -7.2312e+00,\n",
       "        -6.8722e+00, -6.2317e+00, -6.0768e+00, -5.8338e+00, -5.2100e+00,\n",
       "        -5.0316e+00, -4.8122e+00, -4.8287e+00, -4.8191e+00, -4.7682e+00,\n",
       "        -4.8402e+00, -5.0198e+00, -4.8576e+00, -4.6458e+00, -4.6525e+00,\n",
       "        -4.5661e+00, -4.4765e+00, -4.4847e+00, -4.2631e+00, -4.5779e+00,\n",
       "        -4.7897e+00, -4.6694e+00, -5.1281e+00, -4.8903e+00, -5.2669e+00,\n",
       "        -5.0791e+00, -4.8225e+00, -5.4319e+00, -5.7692e+00, -5.0441e+00,\n",
       "        -5.2016e+00, -4.9732e+00, -4.8302e+00, -5.1365e+00, -5.2112e+00,\n",
       "        -5.3023e+00, -5.3787e+00, -5.5397e+00, -5.5151e+00, -5.9245e+00,\n",
       "        -5.8163e+00, -5.9782e+00, -5.2996e+00, -5.4737e+00, -5.5200e+00,\n",
       "        -5.5589e+00, -5.4932e+00, -5.2754e+00, -5.1180e+00, -5.1033e+00,\n",
       "        -4.5851e+00, -5.0620e+00, -4.9830e+00, -4.8531e+00, -4.7613e+00,\n",
       "        -4.5676e+00, -4.4176e+00, -4.2322e+00, -3.9553e+00, -3.8968e+00,\n",
       "        -3.3153e+00, -3.3538e+00, -3.3101e+00, -3.0109e+00, -3.1101e+00,\n",
       "        -3.0272e+00, -2.8937e+00, -2.5479e+00, -2.3547e+00, -2.2384e+00,\n",
       "        -2.1422e+00, -2.1057e+00, -1.9177e+00, -1.9505e+00, -1.6627e+00,\n",
       "        -1.4502e+00, -1.2524e+00, -1.2979e+00, -1.4642e+00, -1.2674e+00,\n",
       "        -1.1984e+00, -1.2984e+00, -9.8874e-01, -1.0098e+00, -9.0500e-01,\n",
       "        -5.9621e-01, -6.3090e-01, -6.4068e-01, -3.6713e-01, -2.6614e-01,\n",
       "        -2.1808e-01, -8.2798e-02,  5.2081e-02, -1.1509e-02,  8.8111e-02,\n",
       "         2.8962e-01,  2.0820e-01,  2.7092e-01,  2.6777e-01,  1.4003e-01,\n",
       "         1.6154e-01,  2.4647e-01,  2.8614e-01,  2.2642e-01,  1.0451e-01,\n",
       "         8.3623e-02,  1.9322e-01,  2.5955e-01,  8.5133e-02,  2.7264e-01,\n",
       "         5.0146e-01,  2.7448e-01,  4.2287e-01,  3.1544e-01,  4.5041e-01,\n",
       "         3.7044e-01,  5.6405e-01,  4.8448e-01,  1.3450e-01, -9.0373e-02,\n",
       "         5.7772e-02,  1.0677e-01,  1.8767e-01, -4.9907e-03,  6.4354e-02,\n",
       "        -2.7083e-01, -1.8163e-01, -1.7749e-01, -5.6782e-02,  1.2425e-01,\n",
       "         2.3342e-02,  1.4714e-01, -5.8618e-02, -1.9365e-01, -1.2403e-01,\n",
       "        -1.3453e-01,  1.1378e-02,  1.7016e-02, -8.6820e-02,  3.9396e-02,\n",
       "        -8.6210e-02, -1.4753e-02, -9.2780e-02,  3.4127e-02,  3.6955e-02,\n",
       "        -1.3153e-01, -1.4904e-01, -1.4469e-01, -1.5524e-01, -3.3728e-01,\n",
       "        -4.2579e-01, -4.5676e-01, -3.9222e-01, -5.9317e-01, -8.0170e-01,\n",
       "        -8.5416e-01, -8.6094e-01, -1.0332e+00, -1.3421e+00, -1.4295e+00,\n",
       "        -1.6835e+00, -1.8187e+00, -1.8138e+00, -1.8555e+00, -1.9938e+00,\n",
       "        -2.1055e+00, -2.3697e+00, -2.3980e+00, -2.3252e+00, -2.6069e+00,\n",
       "        -2.6829e+00, -2.8424e+00, -3.0395e+00, -3.0659e+00, -3.1714e+00,\n",
       "        -3.3547e+00, -3.4451e+00, -3.5045e+00, -3.8124e+00, -4.2795e+00,\n",
       "        -4.4315e+00, -4.5110e+00, -4.5288e+00, -4.8807e+00, -5.1203e+00,\n",
       "        -5.3122e+00, -5.0875e+00, -5.5725e+00, -5.3004e+00, -5.7700e+00,\n",
       "        -5.5036e+00, -5.8694e+00, -6.0784e+00, -5.7300e+00, -5.9752e+00,\n",
       "        -5.9639e+00, -5.5136e+00, -6.3171e+00, -5.9742e+00, -5.9269e+00,\n",
       "        -6.0338e+00, -6.1577e+00, -6.1933e+00, -6.3998e+00, -6.0635e+00,\n",
       "        -5.8210e+00, -6.0519e+00, -5.7662e+00, -6.2019e+00, -5.8175e+00,\n",
       "        -5.4155e+00, -5.4411e+00, -5.2152e+00, -5.2619e+00, -5.0795e+00,\n",
       "        -5.3696e+00, -4.8555e+00, -5.0320e+00, -4.8302e+00, -4.6054e+00,\n",
       "        -5.0078e+00, -5.0252e+00, -5.2503e+00, -5.3520e+00, -4.7763e+00,\n",
       "        -4.6744e+00, -4.7825e+00, -4.7060e+00, -4.3996e+00, -4.4651e+00,\n",
       "        -4.3253e+00, -4.5765e+00, -5.0021e+00, -4.6499e+00, -4.8495e+00,\n",
       "        -4.9247e+00, -5.1852e+00, -5.6371e+00, -5.5545e+00, -5.6588e+00,\n",
       "        -5.5653e+00, -5.5671e+00, -5.8616e+00, -6.0053e+00, -6.1686e+00,\n",
       "        -6.6033e+00, -6.8457e+00, -6.6842e+00, -6.6027e+00, -6.5712e+00,\n",
       "        -6.2666e+00])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   0,   0, 189]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x_input = torch.cat([torch.zeros_like(x), torch.zeros_like(x)], dim=1)\n",
    "first_x_input[0, -1] = x[0, 0]\n",
    "first_x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "first_x_output = model(first_x_input).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.9625, -13.2330, -12.2922, -12.2994, -12.1627, -12.3003, -12.2914,\n",
       "        -11.8946, -11.8871, -11.0082, -10.7952, -10.3780, -10.3103,  -9.7176,\n",
       "         -9.7637,  -9.4829,  -9.4935,  -9.1279,  -9.1220,  -9.1577,  -9.3137,\n",
       "         -9.6153,  -9.3507,  -9.0815,  -9.1525,  -8.8211,  -8.3858,  -7.9498,\n",
       "         -7.2788,  -6.7857,  -6.6121,  -6.2381,  -6.1908,  -6.1728,  -6.0492,\n",
       "         -5.9306,  -5.8768,  -5.6382,  -5.6412,  -5.2648,  -4.9481,  -4.7011,\n",
       "         -4.7615,  -4.5728,  -4.5605,  -4.1412,  -4.1418,  -4.1206,  -3.9943,\n",
       "         -3.9615,  -3.7657,  -3.7484,  -3.3526,  -3.2441,  -2.9082,  -2.9404,\n",
       "         -2.9339,  -2.6680,  -2.7658,  -2.6940,  -2.7051,  -2.4763,  -2.5125,\n",
       "         -2.4400,  -2.3020,  -2.2643,  -2.3682,  -2.2020,  -2.2429,  -2.2758,\n",
       "         -2.3785,  -2.2099,  -2.2819,  -2.4777,  -2.2770,  -2.4424,  -2.5678,\n",
       "         -2.5204,  -2.5705,  -2.6369,  -2.5514,  -2.6978,  -2.7095,  -2.7936,\n",
       "         -2.7543,  -2.7318,  -2.7664,  -2.6829,  -3.1051,  -3.1358,  -3.1831,\n",
       "         -3.0297,  -3.1801,  -3.0383,  -3.1531,  -3.2643,  -3.1993,  -3.3522,\n",
       "         -3.3025,  -3.3886,  -3.1829,  -3.4350,  -3.4616,  -3.2575,  -3.4754,\n",
       "         -3.4897,  -3.6586,  -3.4861,  -3.3159,  -3.5958,  -3.6317,  -3.7004,\n",
       "         -3.9073,  -3.9099,  -3.8546,  -4.0085,  -4.0998,  -4.0416,  -4.1352,\n",
       "         -3.9941,  -4.2599,  -3.9798,  -4.3286,  -4.3872,  -4.4904,  -4.2991,\n",
       "         -4.3693,  -4.3190,  -4.4191,  -4.4214,  -4.5403,  -4.3978,  -4.2696,\n",
       "         -4.1234,  -3.8554,  -4.1989,  -3.7891,  -3.9403,  -4.0519,  -3.7391,\n",
       "         -3.9966,  -3.6092,  -3.8670,  -3.5817,  -3.5739,  -3.6045,  -3.5600,\n",
       "         -3.4444,  -3.5532,  -3.4566,  -3.6225,  -3.4706,  -3.1806,  -3.2128,\n",
       "         -3.2685,  -3.0195,  -3.2019,  -3.0549,  -3.0696,  -3.0173,  -3.0765,\n",
       "         -3.0442,  -3.2695,  -2.9922,  -3.0267,  -2.9317,  -2.8848,  -2.7830,\n",
       "         -2.6078,  -2.6178,  -2.5944,  -2.4599,  -2.3757,  -2.3979,  -2.4680,\n",
       "         -2.4498,  -2.7155,  -2.4788,  -2.5512,  -2.4180,  -2.3758,  -2.4432,\n",
       "         -2.3775,  -2.2790,  -2.3940,  -2.4065,  -2.2381,  -2.2873,  -2.1179,\n",
       "         -2.3424,  -2.2054,  -2.2364,  -2.1726,  -2.2192,  -2.2318,  -2.3972,\n",
       "         -2.4484,  -2.4158,  -2.3927,  -2.4830,  -2.5091,  -2.7189,  -2.5932,\n",
       "         -2.7731,  -2.8593,  -2.8537,  -2.8271,  -2.8542,  -2.9903,  -2.9917,\n",
       "         -3.2977,  -3.5041,  -3.5716,  -3.6991,  -4.2104,  -4.4470,  -4.6219,\n",
       "         -5.0495,  -5.1105,  -5.5413,  -5.8250,  -6.1837,  -6.5303,  -6.4873,\n",
       "         -6.6477,  -7.0896,  -7.5575,  -7.4664,  -8.0961,  -8.1101,  -8.4974,\n",
       "         -8.7716,  -8.7427,  -8.9970,  -9.1729,  -9.0591,  -9.2398,  -9.5094,\n",
       "         -9.2572,  -9.4105,  -9.3380,  -9.2905,  -9.3715,  -9.5429,  -9.9965,\n",
       "        -10.1277, -10.4241, -10.3885, -10.1633, -10.8120, -10.4651, -10.8986,\n",
       "        -11.1639, -10.9406, -10.8537, -10.9230])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x_output[0, :, x.size(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.5277, -12.6183, -11.7072, -11.7662, -11.5636, -11.6795, -11.6077,\n",
       "        -11.3051, -11.2890, -10.4578, -10.2337,  -9.8175,  -9.7567,  -9.2041,\n",
       "         -9.3712,  -9.0331,  -9.0302,  -8.7036,  -8.7306,  -8.7778,  -8.8900,\n",
       "         -9.0959,  -8.8060,  -8.5355,  -8.6070,  -8.3687,  -8.0218,  -7.6326,\n",
       "         -7.0911,  -6.5718,  -6.3698,  -5.9204,  -5.6828,  -5.6120,  -5.5672,\n",
       "         -5.3691,  -5.3630,  -5.0619,  -5.0921,  -4.7758,  -4.4459,  -4.1894,\n",
       "         -4.2153,  -4.0333,  -4.0095,  -3.6975,  -3.5521,  -3.3636,  -3.2109,\n",
       "         -3.1330,  -3.0753,  -3.1495,  -2.7864,  -2.6340,  -2.3848,  -2.3327,\n",
       "         -2.1958,  -2.1415,  -2.2187,  -2.2180,  -2.1524,  -1.9440,  -2.0950,\n",
       "         -2.0151,  -1.8984,  -1.8868,  -2.0494,  -2.0144,  -1.9881,  -2.0782,\n",
       "         -2.1385,  -2.0467,  -2.0528,  -2.3017,  -2.1262,  -2.1894,  -2.1996,\n",
       "         -2.1059,  -2.1616,  -2.2772,  -2.2939,  -2.5053,  -2.4807,  -2.3863,\n",
       "         -2.5066,  -2.5174,  -2.5686,  -2.4618,  -2.8314,  -2.8575,  -2.9205,\n",
       "         -2.8074,  -2.9898,  -2.8259,  -2.9323,  -2.9808,  -2.9725,  -3.0298,\n",
       "         -3.0520,  -3.1225,  -3.0143,  -3.2139,  -3.2124,  -2.9768,  -3.1112,\n",
       "         -3.1506,  -3.3476,  -3.1925,  -3.1234,  -3.2887,  -3.3428,  -3.4336,\n",
       "         -3.7133,  -3.5738,  -3.5676,  -3.6908,  -3.8579,  -3.8066,  -3.8440,\n",
       "         -3.8789,  -4.0159,  -3.7148,  -3.9957,  -4.0117,  -4.2337,  -4.0091,\n",
       "         -3.9494,  -3.9573,  -3.9978,  -4.0712,  -4.2579,  -4.0530,  -4.0185,\n",
       "         -3.8488,  -3.6195,  -3.9529,  -3.7130,  -3.8233,  -3.8504,  -3.4952,\n",
       "         -3.7004,  -3.3047,  -3.4596,  -3.3193,  -3.2794,  -3.3931,  -3.3855,\n",
       "         -3.2020,  -3.3107,  -3.2019,  -3.4358,  -3.1495,  -2.7658,  -2.8766,\n",
       "         -3.0107,  -2.9191,  -3.0307,  -2.9038,  -2.9077,  -2.8242,  -2.8539,\n",
       "         -2.8179,  -3.0733,  -2.7991,  -2.6933,  -2.5545,  -2.6290,  -2.5842,\n",
       "         -2.4624,  -2.5198,  -2.5261,  -2.3423,  -2.1957,  -2.2501,  -2.4492,\n",
       "         -2.3595,  -2.6243,  -2.3997,  -2.4837,  -2.3813,  -2.4267,  -2.4783,\n",
       "         -2.4392,  -2.3082,  -2.4300,  -2.4378,  -2.3992,  -2.4841,  -2.3125,\n",
       "         -2.5302,  -2.3633,  -2.3851,  -2.2037,  -2.2056,  -2.2131,  -2.4845,\n",
       "         -2.5548,  -2.5001,  -2.4205,  -2.5234,  -2.5363,  -2.8844,  -2.6669,\n",
       "         -2.9365,  -3.0657,  -3.0814,  -3.1432,  -3.1800,  -3.3844,  -3.3870,\n",
       "         -3.9022,  -4.1582,  -4.3298,  -4.6137,  -5.0684,  -5.3740,  -5.5087,\n",
       "         -5.9414,  -5.9953,  -6.2949,  -6.5971,  -6.8202,  -7.1901,  -7.0922,\n",
       "         -7.3099,  -7.8671,  -8.2644,  -8.2316,  -8.9077,  -8.6929,  -8.9225,\n",
       "         -9.0334,  -8.8158,  -8.8739,  -8.9983,  -8.9292,  -9.0594,  -9.3038,\n",
       "         -8.9888,  -9.1593,  -9.1960,  -9.0868,  -9.1644,  -9.2935,  -9.6535,\n",
       "         -9.8282, -10.1757, -10.1884, -10.0333, -10.5909, -10.3759, -10.6619,\n",
       "        -10.9506, -10.8310, -10.8242, -10.8131])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x_output[0, :, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incremental_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_forward(self, all_x, initial_input=None, c=None, g=None,\n",
    "                        T=100, test_inputs=None,\n",
    "                        tqdm=lambda x: x, softmax=False, quantize=False,\n",
    "                        log_scale_min=-7.0):\n",
    "    print(\"patching worked!\")\n",
    "    \"\"\"Incremental forward step\n",
    "\n",
    "    Due to linearized convolutions, inputs of shape (B x C x T) are reshaped\n",
    "    to (B x T x C) internally and fed to the network for each time step.\n",
    "    Input of each time step will be of shape (B x 1 x C).\n",
    "\n",
    "    Args:\n",
    "        initial_input (Tensor): Initial decoder input, (B x C x 1)\n",
    "        c (Tensor): Local conditioning features, shape (B x C' x T)\n",
    "        g (Tensor): Global conditioning features, shape (B x C'' or B x C''x 1)\n",
    "        T (int): Number of time steps to generate.\n",
    "        test_inputs (Tensor): Teacher forcing inputs (for debugging)\n",
    "        tqdm (lamda) : tqdm\n",
    "        softmax (bool) : Whether applies softmax or not\n",
    "        quantize (bool): Whether quantize softmax output before feeding the\n",
    "            network output to input for the next time step. TODO: rename\n",
    "        log_scale_min (float):  Log scale minimum value.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Generated one-hot encoded samples. B x C x T　\n",
    "            or scaler vector B x 1 x T\n",
    "    \"\"\"\n",
    "    self.clear_buffer()\n",
    "    B = 1\n",
    "\n",
    "    # Note: shape should be **(B x T x C)**, not (B x C x T) opposed to\n",
    "    # batch forward due to linealized convolution\n",
    "    if test_inputs is not None:\n",
    "        if self.scalar_input:\n",
    "            if test_inputs.size(1) == 1:\n",
    "                test_inputs = test_inputs.transpose(1, 2).contiguous()\n",
    "        else:\n",
    "            if test_inputs.size(1) == self.out_channels:\n",
    "                test_inputs = test_inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        B = test_inputs.size(0)\n",
    "        if T is None:\n",
    "            T = test_inputs.size(1)\n",
    "        else:\n",
    "            T = max(T, test_inputs.size(1))\n",
    "    # cast to int in case of numpy.int64...\n",
    "    T = int(T)\n",
    "\n",
    "    # Global conditioning\n",
    "    if g is not None:\n",
    "        if self.embed_speakers is not None:\n",
    "            g = self.embed_speakers(g.view(B, -1))\n",
    "            # (B x gin_channels, 1)\n",
    "            g = g.transpose(1, 2)\n",
    "            assert g.dim() == 3\n",
    "#     g_btc = _expand_global_features(B, T, g, bct=False)\n",
    "\n",
    "    # Local conditioning\n",
    "    if c is not None and self.upsample_conv is not None:\n",
    "        # B x 1 x C x T\n",
    "        c = c.unsqueeze(1)\n",
    "        for f in self.upsample_conv:\n",
    "            c = f(c)\n",
    "        # B x C x T\n",
    "        c = c.squeeze(1)\n",
    "        assert c.size(-1) == T\n",
    "    if c is not None and c.size(-1) == T:\n",
    "        c = c.transpose(1, 2).contiguous()\n",
    "\n",
    "    outputs = []\n",
    "    if initial_input is None:\n",
    "        if self.scalar_input:\n",
    "            initial_input = torch.zeros(B, 1, 1)\n",
    "        else:\n",
    "            initial_input = torch.zeros(B, 1, self.out_channels)\n",
    "            initial_input[:, :, 127] = 1  # TODO: is this ok?\n",
    "        # https://github.com/pytorch/pytorch/issues/584#issuecomment-275169567\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            initial_input = initial_input.cuda()\n",
    "    else:\n",
    "        if initial_input.size(1) == self.out_channels:\n",
    "            initial_input = initial_input.transpose(1, 2).contiguous()\n",
    "\n",
    "    current_input = initial_input\n",
    "\n",
    "    for t in tqdm(range(all_x.size(-1))):\n",
    "        if t % 1000 == 0:\n",
    "            print(\"iteration\", t)\n",
    "        if test_inputs is not None and t < test_inputs.size(1):\n",
    "            current_input = test_inputs[:, t, :].unsqueeze(1)\n",
    "        else:\n",
    "            if t > 0:\n",
    "#                 print(\"x.size()\", all_x.size())\n",
    "                current_input = all_x[:, :, t-1]\n",
    "\n",
    "        # Conditioning features for single time step\n",
    "        ct = None if c is None else c[:, t, :].unsqueeze(1)\n",
    "        gt = None if g is None else g_btc[:, t, :].unsqueeze(1)\n",
    "\n",
    "        x = current_input\n",
    "        x = self.first_conv.incremental_forward(x)\n",
    "        skips = None\n",
    "        for f in self.conv_layers:\n",
    "            x, h = f.incremental_forward(x, ct, gt)\n",
    "            if self.legacy:\n",
    "                skips = h if skips is None else (skips + h) * math.sqrt(0.5)\n",
    "            else:\n",
    "                skips = h if skips is None else (skips + h)\n",
    "        x = skips\n",
    "        for f in self.last_conv_layers:\n",
    "            try:\n",
    "                x = f.incremental_forward(x)\n",
    "            except AttributeError:\n",
    "                x = f(x)\n",
    "\n",
    "        # Generate next input by sampling\n",
    "        if self.scalar_input:\n",
    "            x = sample_from_discretized_mix_logistic(\n",
    "                x.view(B, -1, 1), log_scale_min=log_scale_min)\n",
    "        else:\n",
    "            x = F.softmax(x.view(B, -1), dim=1) if softmax else x.view(B, -1)\n",
    "            if quantize:\n",
    "                sample = np.random.choice(\n",
    "                    np.arange(self.out_channels), p=x.view(-1).data.cpu().numpy())\n",
    "                x.zero_()\n",
    "                x[:, sample] = 1.0\n",
    "        outputs += [x.data]\n",
    "    # T x B x C\n",
    "    outputs = torch.stack(outputs)\n",
    "    # B x C x T\n",
    "    outputs = outputs.transpose(0, 1).transpose(1, 2).contiguous()\n",
    "\n",
    "    self.clear_buffer()\n",
    "    return outputs\n",
    "\n",
    "import types\n",
    "model.incremental_forward = types.MethodType(incremental_forward, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uncompressed = x # x[:, :8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching worked!\n",
      "iteration 0\n",
      "iteration 1000\n",
      "iteration 2000\n",
      "iteration 3000\n",
      "iteration 4000\n",
      "iteration 5000\n",
      "iteration 6000\n",
      "iteration 7000\n",
      "iteration 8000\n",
      "iteration 9000\n",
      "iteration 10000\n",
      "iteration 11000\n",
      "iteration 12000\n",
      "iteration 13000\n",
      "iteration 14000\n",
      "iteration 15000\n",
      "iteration 16000\n",
      "iteration 17000\n",
      "iteration 18000\n",
      "iteration 19000\n",
      "iteration 20000\n",
      "iteration 21000\n",
      "iteration 22000\n",
      "iteration 23000\n",
      "iteration 24000\n",
      "iteration 25000\n",
      "iteration 26000\n",
      "iteration 27000\n",
      "iteration 28000\n",
      "iteration 29000\n",
      "iteration 30000\n",
      "iteration 31000\n",
      "iteration 32000\n"
     ]
    }
   ],
   "source": [
    "logits = model.incremental_forward(model.one_hot(x_uncompressed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def categoricals_append(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    def append(state, data):\n",
    "        data = np.ravel(data)\n",
    "        return non_uniforms_append(precision, cdfs)(state, data)\n",
    "    return append\n",
    "\n",
    "def categoricals_pop(probs, precision):\n",
    "    \"\"\"Assume that the last dim of probs contains the probability vectors,\n",
    "    i.e. np.sum(probs, axis=-1) == ones\"\"\"\n",
    "    # Flatten all but last dim of probs\n",
    "    data_shape = np.shape(probs)[:-1]\n",
    "    probs = np.reshape(probs, (-1, np.shape(probs)[-1]))\n",
    "    cdfs = [categorical_cdf(p, precision) for p in probs]\n",
    "    ppfs = [categorical_ppf(p, precision) for p in probs]\n",
    "\n",
    "    def pop(state):\n",
    "        state, symbols = non_uniforms_pop(precision, ppfs, cdfs)(state)\n",
    "        return state, np.reshape(symbols, data_shape)\n",
    "    return pop\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32744, 256)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = np.array([[1/32, 31/32], [1/4, 3/4]])\n",
    "probs = F.softmax(logits, dim=1).squeeze().numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(208)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_uncompressed[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_uncompressed.squeeze().numpy()\n",
    "# print(\"data\", data)\n",
    "state = rans.x_init\n",
    "# print(\"state 1\", state)\n",
    "state = util.categoricals_append(probs, precision)(state, data)\n",
    "# print(\"state 2\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint32'), (3856,))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_state = rans.flatten(state)\n",
    "flat_state.dtype, flat_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1229253112033195"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32744 / (3856*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_forward_recover(self, state, length, initial_input=None, c=None, g=None,\n",
    "                        T=100, test_inputs=None,\n",
    "                        tqdm=lambda x: x, softmax=False, quantize=False,\n",
    "                        log_scale_min=-7.0):\n",
    "    print(\"patching worked!\")\n",
    "    \"\"\"Incremental forward step\n",
    "\n",
    "    Due to linearized convolutions, inputs of shape (B x C x T) are reshaped\n",
    "    to (B x T x C) internally and fed to the network for each time step.\n",
    "    Input of each time step will be of shape (B x 1 x C).\n",
    "\n",
    "    Args:\n",
    "        initial_input (Tensor): Initial decoder input, (B x C x 1)\n",
    "        c (Tensor): Local conditioning features, shape (B x C' x T)\n",
    "        g (Tensor): Global conditioning features, shape (B x C'' or B x C''x 1)\n",
    "        T (int): Number of time steps to generate.\n",
    "        test_inputs (Tensor): Teacher forcing inputs (for debugging)\n",
    "        tqdm (lamda) : tqdm\n",
    "        softmax (bool) : Whether applies softmax or not\n",
    "        quantize (bool): Whether quantize softmax output before feeding the\n",
    "            network output to input for the next time step. TODO: rename\n",
    "        log_scale_min (float):  Log scale minimum value.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Generated one-hot encoded samples. B x C x T　\n",
    "            or scaler vector B x 1 x T\n",
    "    \"\"\"\n",
    "    self.clear_buffer()\n",
    "    B = 1\n",
    "\n",
    "    # Note: shape should be **(B x T x C)**, not (B x C x T) opposed to\n",
    "    # batch forward due to linealized convolution\n",
    "    if test_inputs is not None:\n",
    "        if self.scalar_input:\n",
    "            if test_inputs.size(1) == 1:\n",
    "                test_inputs = test_inputs.transpose(1, 2).contiguous()\n",
    "        else:\n",
    "            if test_inputs.size(1) == self.out_channels:\n",
    "                test_inputs = test_inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        B = test_inputs.size(0)\n",
    "        if T is None:\n",
    "            T = test_inputs.size(1)\n",
    "        else:\n",
    "            T = max(T, test_inputs.size(1))\n",
    "    # cast to int in case of numpy.int64...\n",
    "    T = int(T)\n",
    "\n",
    "    # Global conditioning\n",
    "    if g is not None:\n",
    "        if self.embed_speakers is not None:\n",
    "            g = self.embed_speakers(g.view(B, -1))\n",
    "            # (B x gin_channels, 1)\n",
    "            g = g.transpose(1, 2)\n",
    "            assert g.dim() == 3\n",
    "#     g_btc = _expand_global_features(B, T, g, bct=False)\n",
    "\n",
    "    # Local conditioning\n",
    "    if c is not None and self.upsample_conv is not None:\n",
    "        # B x 1 x C x T\n",
    "        c = c.unsqueeze(1)\n",
    "        for f in self.upsample_conv:\n",
    "            c = f(c)\n",
    "        # B x C x T\n",
    "        c = c.squeeze(1)\n",
    "        assert c.size(-1) == T\n",
    "    if c is not None and c.size(-1) == T:\n",
    "        c = c.transpose(1, 2).contiguous()\n",
    "\n",
    "    outputs = []\n",
    "    if initial_input is None:\n",
    "        if self.scalar_input:\n",
    "            initial_input = torch.zeros(B, 1, 1)\n",
    "        else:\n",
    "            initial_input = torch.zeros(B, 1, self.out_channels)\n",
    "            initial_input[:, :, 127] = 1  # TODO: is this ok?\n",
    "        # https://github.com/pytorch/pytorch/issues/584#issuecomment-275169567\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            initial_input = initial_input.cuda()\n",
    "    else:\n",
    "        if initial_input.size(1) == self.out_channels:\n",
    "            initial_input = initial_input.transpose(1, 2).contiguous()\n",
    "\n",
    "    current_input = initial_input\n",
    "    recovered_data = np.zeros(length, dtype=np.int32)\n",
    "    for t in tqdm(range(length)):\n",
    "        if t % 1000 == 0:\n",
    "            print(\"iteration\", t)\n",
    "        if test_inputs is not None and t < test_inputs.size(1):\n",
    "            current_input = test_inputs[:, t, :].unsqueeze(1)\n",
    "        else:\n",
    "            if t > 0:\n",
    "                current_input_scalar = recovered_data[t-1]\n",
    "#                 print(\"current_input_scalar\", current_input_scalar)\n",
    "                current_input = torch.zeros(1, 256)\n",
    "                current_input[0, current_input_scalar] = 1.\n",
    "                # all_x[:, :, t-1]\n",
    "                \n",
    "\n",
    "        # Conditioning features for single time step\n",
    "        ct = None if c is None else c[:, t, :].unsqueeze(1)\n",
    "        gt = None if g is None else g_btc[:, t, :].unsqueeze(1)\n",
    "\n",
    "        x = current_input\n",
    "        x = self.first_conv.incremental_forward(x)\n",
    "        skips = None\n",
    "        for f in self.conv_layers:\n",
    "            x, h = f.incremental_forward(x, ct, gt)\n",
    "            if self.legacy:\n",
    "                skips = h if skips is None else (skips + h) * math.sqrt(0.5)\n",
    "            else:\n",
    "                skips = h if skips is None else (skips + h)\n",
    "        x = skips\n",
    "        for f in self.last_conv_layers:\n",
    "            try:\n",
    "                x = f.incremental_forward(x)\n",
    "            except AttributeError:\n",
    "                x = f(x)\n",
    "\n",
    "        # Generate next input by sampling\n",
    "        if self.scalar_input:\n",
    "            x = sample_from_discretized_mix_logistic(\n",
    "                x.view(B, -1, 1), log_scale_min=log_scale_min)\n",
    "        else:\n",
    "            x = F.softmax(x.view(B, -1), dim=1) if softmax else x.view(B, -1)\n",
    "            if quantize:\n",
    "                sample = np.random.choice(\n",
    "                    np.arange(self.out_channels), p=x.view(-1).data.cpu().numpy())\n",
    "                x.zero_()\n",
    "                x[:, sample] = 1.0\n",
    "        outputs += [x.data]\n",
    "        probs = F.softmax(outputs[-1], dim=-1).numpy()\n",
    "#         print(f\"probs at t={t}: {probs}\")\n",
    "        state, scalar_input = util.categoricals_pop(probs, precision)(state)\n",
    "#         print(\"output.shape\", output.shape)\n",
    "        scalar_input = scalar_input[0]\n",
    "        recovered_data[t] = scalar_input\n",
    "        print(\"scalar_input: \", scalar_input)\n",
    "\n",
    "    # T x B x C\n",
    "    outputs = torch.stack(outputs)\n",
    "    # B x C x T\n",
    "    outputs = outputs.transpose(0, 1).transpose(1, 2).contiguous()\n",
    "\n",
    "\n",
    "    self.clear_buffer()\n",
    "    return recovered_data\n",
    "\n",
    "import types\n",
    "model.incremental_forward_recover = types.MethodType(incremental_forward_recover, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([189,  68,  48,  42,  41,  36,  29,  22,  18,  16,  16,  18,  23,\n",
       "        30,  42,  60,  78,  83,  75,  70,  95, 193, 209, 218, 224, 224,\n",
       "       221, 215, 199, 179, 203, 219, 222, 220, 216, 208, 190, 146, 169,\n",
       "       199, 208, 204, 184,  73,  45,  32,  28,  29,  32,  36,  39,  38,\n",
       "        33,  29,  27,  29,  37,  57, 111, 181, 189, 185, 146,  71,  72,\n",
       "       188, 217, 227, 230, 229, 224, 215, 212, 217, 218, 217, 216, 212,\n",
       "       199, 169,  86,  89,  83,  75,  79,  81,  71,  56,  45,  39,  37,\n",
       "        41,  50,  61,  67,  68,  66,  57,  53,  63])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching worked!\n",
      "iteration 0\n",
      "scalar_input:  189\n",
      "scalar_input:  68\n",
      "scalar_input:  48\n",
      "scalar_input:  42\n",
      "scalar_input:  41\n",
      "scalar_input:  36\n",
      "scalar_input:  29\n",
      "scalar_input:  22\n",
      "scalar_input:  18\n",
      "scalar_input:  16\n",
      "scalar_input:  16\n",
      "scalar_input:  18\n",
      "scalar_input:  23\n",
      "scalar_input:  30\n",
      "scalar_input:  42\n",
      "scalar_input:  60\n",
      "scalar_input:  78\n",
      "scalar_input:  83\n",
      "scalar_input:  75\n",
      "scalar_input:  70\n",
      "scalar_input:  95\n",
      "scalar_input:  193\n",
      "scalar_input:  209\n",
      "scalar_input:  218\n",
      "scalar_input:  224\n",
      "scalar_input:  224\n",
      "scalar_input:  221\n",
      "scalar_input:  215\n",
      "scalar_input:  199\n",
      "scalar_input:  179\n",
      "scalar_input:  203\n",
      "scalar_input:  219\n",
      "scalar_input:  222\n",
      "scalar_input:  220\n",
      "scalar_input:  216\n",
      "scalar_input:  208\n",
      "scalar_input:  190\n",
      "scalar_input:  146\n",
      "scalar_input:  169\n",
      "scalar_input:  199\n",
      "scalar_input:  208\n",
      "scalar_input:  204\n",
      "scalar_input:  184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-330-20db26133e3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecovered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_forward_recover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-328-a2a7b09bfd45>\u001b[0m in \u001b[0;36mincremental_forward_recover\u001b[0;34m(self, state, length, initial_input, c, g, T, test_inputs, tqdm, softmax, quantize, log_scale_min)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mskips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mskips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mskips\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mskips\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wavenet_vocoder/wavenet_vocoder/modules.py\u001b[0m in \u001b[0;36mincremental_forward\u001b[0;34m(self, x, c, g)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mincremental_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_incremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wavenet_vocoder/wavenet_vocoder/modules.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, c, g, is_incremental)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_incremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0msplitdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincremental_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0msplitdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wavenet_vocoder/wavenet_vocoder/conv.py\u001b[0m in \u001b[0;36mincremental_forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# run forward pre hooks (e.g., weight norm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# reshape weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wavelet/lib/python3.6/site-packages/torch/nn/utils/weight_norm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/wavelet/lib/python3.6/site-packages/torch/nn/utils/weight_norm.py\u001b[0m in \u001b[0;36mcompute_weight\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_weight_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recovered_data = model.incremental_forward_recover(state, length=data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [1 1]\n",
      "state 1 (2147483648, ())\n",
      "state 2 (2956104068, ())\n",
      "state (2147483648, ())\n",
      "recovered_bits [1 1]\n"
     ]
    }
   ],
   "source": [
    "state, recovered_data = util.categoricals_pop(probs, precision)(state)\n",
    "print(\"state\", state)\n",
    "print(\"recovered_bits\", recovered_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
